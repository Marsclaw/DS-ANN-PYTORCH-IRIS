{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "raKgIwx2993Q"
   },
   "source": [
    "# Basic PyTorch Neural Network\n",
    "Now it's time to put the pieces together. In this section we'll:\n",
    "* create a multi-layer deep learning model\n",
    "* load data\n",
    "* train and validate the model<br>\n",
    "\n",
    "We'll also introduce a new step:\n",
    "* save and load a trained model\n",
    "\n",
    "Our goal is to develop a model capable of classifying an iris plant based on four features. This is a multi-class classification where each sample can belong to ONE of 3 classes (<em>Iris setosa</em>, <em>Iris virginica</em> or <em>Iris versicolor</em>). The network will have 4 input neurons (flower dimensions) and 3 output neurons (scores). Our loss function will compare the target label (ground truth) to the corresponding output score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoNBGGHd993X"
   },
   "source": [
    "<div class=\"alert alert-info\"><strong>NOTE:</strong> Multi-class classifications usually involve converting the target vector to a one_hot encoded matrix. That is, if 5 labels show up as<br>\n",
    "<pre style='background-color:rgb(217,237,247)'>tensor([0,2,1,0,1])</pre>\n",
    "then we would encode them as:\n",
    "<pre style='background-color:rgb(217,237,247)'>tensor([[1, 0, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 0],\n",
    "        [1, 0, 0],\n",
    "        [0, 1, 0]])</pre>\n",
    "This is easily accomplished with <a href='https://pytorch.org/docs/stable/nn.html#one-hot'><strong><tt>torch.nn.functional.one_hot()</tt></strong></a>.<br>\n",
    "However, our loss function <a href='https://pytorch.org/docs/stable/nn.html#crossentropyloss'><strong><tt>torch.nn.CrossEntropyLoss()</tt></strong></a> takes care of this for us.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7wgaM1K993Y"
   },
   "source": [
    "## Perform standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tBWltSvl993Y",
    "outputId": "fec00073-ebd8-46fa-869d-1f60c83f01fb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vXOvuc6993Z"
   },
   "source": [
    "## Create a model class\n",
    "For this exercise we're using the Iris dataset. Since a single straight line can't classify three flowers we should include at least one hidden layer in our model.\n",
    "\n",
    "In the forward section we'll use the <a href='https://en.wikipedia.org/wiki/Rectifier_(neural_networks)'>rectified linear unit</a> (ReLU)  function<br>\n",
    "$\\quad f(x)=max(0,x)$<br>\n",
    "as our activation function. This is available as a full module <a href='https://pytorch.org/docs/stable/nn.html#relu'><strong><tt>torch.nn.ReLU</tt></strong></a> or as just a functional call <a href='https://pytorch.org/docs/stable/nn.html#id27'><strong><tt>torch.nn.functional.relu</tt></strong></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_OyErwa993a"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)    # input layer\n",
    "        self.fc2 = nn.Linear(h1, h2)            # hidden layer\n",
    "        self.out = nn.Linear(h2, out_features)  # output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKOwzcXa993a"
   },
   "outputs": [],
   "source": [
    "# Instantiate the Model class using parameter defaults:\n",
    "torch.manual_seed(32)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFdZiJX0993a"
   },
   "source": [
    "## Load the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2biy56dR993b",
    "outputId": "d0e54021-491a-4b83-9361-9b4dfe8cc0b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\iris.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tphoIdHD993b",
    "outputId": "23228206-4c4f-4bc1-e258-1730c2da4daa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ],\n",
       "       [5.4, 3.9, 1.7, 0.4, 0. ],\n",
       "       [4.6, 3.4, 1.4, 0.3, 0. ],\n",
       "       [5. , 3.4, 1.5, 0.2, 0. ],\n",
       "       [4.4, 2.9, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5.4, 3.7, 1.5, 0.2, 0. ],\n",
       "       [4.8, 3.4, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.1, 0. ],\n",
       "       [4.3, 3. , 1.1, 0.1, 0. ],\n",
       "       [5.8, 4. , 1.2, 0.2, 0. ],\n",
       "       [5.7, 4.4, 1.5, 0.4, 0. ],\n",
       "       [5.4, 3.9, 1.3, 0.4, 0. ],\n",
       "       [5.1, 3.5, 1.4, 0.3, 0. ],\n",
       "       [5.7, 3.8, 1.7, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.5, 0.3, 0. ],\n",
       "       [5.4, 3.4, 1.7, 0.2, 0. ],\n",
       "       [5.1, 3.7, 1.5, 0.4, 0. ],\n",
       "       [4.6, 3.6, 1. , 0.2, 0. ],\n",
       "       [5.1, 3.3, 1.7, 0.5, 0. ],\n",
       "       [4.8, 3.4, 1.9, 0.2, 0. ],\n",
       "       [5. , 3. , 1.6, 0.2, 0. ],\n",
       "       [5. , 3.4, 1.6, 0.4, 0. ],\n",
       "       [5.2, 3.5, 1.5, 0.2, 0. ],\n",
       "       [5.2, 3.4, 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3.1, 1.6, 0.2, 0. ],\n",
       "       [5.4, 3.4, 1.5, 0.4, 0. ],\n",
       "       [5.2, 4.1, 1.5, 0.1, 0. ],\n",
       "       [5.5, 4.2, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5. , 3.2, 1.2, 0.2, 0. ],\n",
       "       [5.5, 3.5, 1.3, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [4.4, 3. , 1.3, 0.2, 0. ],\n",
       "       [5.1, 3.4, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.3, 0.3, 0. ],\n",
       "       [4.5, 2.3, 1.3, 0.3, 0. ],\n",
       "       [4.4, 3.2, 1.3, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.6, 0.6, 0. ],\n",
       "       [5.1, 3.8, 1.9, 0.4, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.6, 0.2, 0. ],\n",
       "       [4.6, 3.2, 1.4, 0.2, 0. ],\n",
       "       [5.3, 3.7, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.3, 1.4, 0.2, 0. ],\n",
       "       [7. , 3.2, 4.7, 1.4, 1. ],\n",
       "       [6.4, 3.2, 4.5, 1.5, 1. ],\n",
       "       [6.9, 3.1, 4.9, 1.5, 1. ],\n",
       "       [5.5, 2.3, 4. , 1.3, 1. ],\n",
       "       [6.5, 2.8, 4.6, 1.5, 1. ],\n",
       "       [5.7, 2.8, 4.5, 1.3, 1. ],\n",
       "       [6.3, 3.3, 4.7, 1.6, 1. ],\n",
       "       [4.9, 2.4, 3.3, 1. , 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3, 1. ],\n",
       "       [5.2, 2.7, 3.9, 1.4, 1. ],\n",
       "       [5. , 2. , 3.5, 1. , 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5, 1. ],\n",
       "       [6. , 2.2, 4. , 1. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4, 1. ],\n",
       "       [5.6, 2.9, 3.6, 1.3, 1. ],\n",
       "       [6.7, 3.1, 4.4, 1.4, 1. ],\n",
       "       [5.6, 3. , 4.5, 1.5, 1. ],\n",
       "       [5.8, 2.7, 4.1, 1. , 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5, 1. ],\n",
       "       [5.6, 2.5, 3.9, 1.1, 1. ],\n",
       "       [5.9, 3.2, 4.8, 1.8, 1. ],\n",
       "       [6.1, 2.8, 4. , 1.3, 1. ],\n",
       "       [6.3, 2.5, 4.9, 1.5, 1. ],\n",
       "       [6.1, 2.8, 4.7, 1.2, 1. ],\n",
       "       [6.4, 2.9, 4.3, 1.3, 1. ],\n",
       "       [6.6, 3. , 4.4, 1.4, 1. ],\n",
       "       [6.8, 2.8, 4.8, 1.4, 1. ],\n",
       "       [6.7, 3. , 5. , 1.7, 1. ],\n",
       "       [6. , 2.9, 4.5, 1.5, 1. ],\n",
       "       [5.7, 2.6, 3.5, 1. , 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1, 1. ],\n",
       "       [5.5, 2.4, 3.7, 1. , 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2, 1. ],\n",
       "       [6. , 2.7, 5.1, 1.6, 1. ],\n",
       "       [5.4, 3. , 4.5, 1.5, 1. ],\n",
       "       [6. , 3.4, 4.5, 1.6, 1. ],\n",
       "       [6.7, 3.1, 4.7, 1.5, 1. ],\n",
       "       [6.3, 2.3, 4.4, 1.3, 1. ],\n",
       "       [5.6, 3. , 4.1, 1.3, 1. ],\n",
       "       [5.5, 2.5, 4. , 1.3, 1. ],\n",
       "       [5.5, 2.6, 4.4, 1.2, 1. ],\n",
       "       [6.1, 3. , 4.6, 1.4, 1. ],\n",
       "       [5.8, 2.6, 4. , 1.2, 1. ],\n",
       "       [5. , 2.3, 3.3, 1. , 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3, 1. ],\n",
       "       [5.7, 3. , 4.2, 1.2, 1. ],\n",
       "       [5.7, 2.9, 4.2, 1.3, 1. ],\n",
       "       [6.2, 2.9, 4.3, 1.3, 1. ],\n",
       "       [5.1, 2.5, 3. , 1.1, 1. ],\n",
       "       [5.7, 2.8, 4.1, 1.3, 1. ],\n",
       "       [6.3, 3.3, 6. , 2.5, 2. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [7.1, 3. , 5.9, 2.1, 2. ],\n",
       "       [6.3, 2.9, 5.6, 1.8, 2. ],\n",
       "       [6.5, 3. , 5.8, 2.2, 2. ],\n",
       "       [7.6, 3. , 6.6, 2.1, 2. ],\n",
       "       [4.9, 2.5, 4.5, 1.7, 2. ],\n",
       "       [7.3, 2.9, 6.3, 1.8, 2. ],\n",
       "       [6.7, 2.5, 5.8, 1.8, 2. ],\n",
       "       [7.2, 3.6, 6.1, 2.5, 2. ],\n",
       "       [6.5, 3.2, 5.1, 2. , 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9, 2. ],\n",
       "       [6.8, 3. , 5.5, 2.1, 2. ],\n",
       "       [5.7, 2.5, 5. , 2. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4, 2. ],\n",
       "       [6.4, 3.2, 5.3, 2.3, 2. ],\n",
       "       [6.5, 3. , 5.5, 1.8, 2. ],\n",
       "       [7.7, 3.8, 6.7, 2.2, 2. ],\n",
       "       [7.7, 2.6, 6.9, 2.3, 2. ],\n",
       "       [6. , 2.2, 5. , 1.5, 2. ],\n",
       "       [6.9, 3.2, 5.7, 2.3, 2. ],\n",
       "       [5.6, 2.8, 4.9, 2. , 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. , 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.1, 2. ],\n",
       "       [7.2, 3.2, 6. , 1.8, 2. ],\n",
       "       [6.2, 2.8, 4.8, 1.8, 2. ],\n",
       "       [6.1, 3. , 4.9, 1.8, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.1, 2. ],\n",
       "       [7.2, 3. , 5.8, 1.6, 2. ],\n",
       "       [7.4, 2.8, 6.1, 1.9, 2. ],\n",
       "       [7.9, 3.8, 6.4, 2. , 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2, 2. ],\n",
       "       [6.3, 2.8, 5.1, 1.5, 2. ],\n",
       "       [6.1, 2.6, 5.6, 1.4, 2. ],\n",
       "       [7.7, 3. , 6.1, 2.3, 2. ],\n",
       "       [6.3, 3.4, 5.6, 2.4, 2. ],\n",
       "       [6.4, 3.1, 5.5, 1.8, 2. ],\n",
       "       [6. , 3. , 4.8, 1.8, 2. ],\n",
       "       [6.9, 3.1, 5.4, 2.1, 2. ],\n",
       "       [6.7, 3.1, 5.6, 2.4, 2. ],\n",
       "       [6.9, 3.1, 5.1, 2.3, 2. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [6.8, 3.2, 5.9, 2.3, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.5, 2. ],\n",
       "       [6.7, 3. , 5.2, 2.3, 2. ],\n",
       "       [6.3, 2.5, 5. , 1.9, 2. ],\n",
       "       [6.5, 3. , 5.2, 2. , 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3, 2. ],\n",
       "       [5.9, 3. , 5.1, 1.8, 2. ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6JxwR5w993b"
   },
   "source": [
    "## Perform Train/Test/Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sd3gpq58993c"
   },
   "outputs": [],
   "source": [
    "X = df.drop('target',axis=1).values\n",
    "y = df['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "# y_train = F.one_hot(torch.LongTensor(y_train))  # not needed with Cross Entropy Loss\n",
    "# y_test = F.one_hot(torch.LongTensor(y_test))\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uG-GWXBn993c"
   },
   "source": [
    "## Prepare DataLoader\n",
    "For this analysis we don't need to create a Dataset object, but we should take advantage of PyTorch's DataLoader tool. Even though our dataset is small (120 training samples), we'll load it into our model in two batches. This technique becomes very helpful with large datasets.\n",
    "\n",
    "Note that scikit-learn already shuffled the source dataset before preparing train and test sets. We'll still benefit from the DataLoader shuffle utility for model training if we make multiple passes throught the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kA8LhJe0993c"
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(X_train, batch_size=60, shuffle=True)\n",
    "\n",
    "testloader = DataLoader(X_test, batch_size=60, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKDSs7F_993c"
   },
   "source": [
    "## Define loss equations and optimizations\n",
    "As before, we'll utilize <a href='https://en.wikipedia.org/wiki/Cross_entropy'>Cross Entropy</a> with <a href='https://pytorch.org/docs/stable/nn.html#crossentropyloss'><strong><tt>torch.nn.CrossEntropyLoss()</tt></strong></a><br>\n",
    "For the optimizer, we'll use a variation of Stochastic Gradient Descent called <a href='https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam'>Adam</a> (short for Adaptive Moment Estimation), with <a href='https://pytorch.org/docs/stable/optim.html#torch.optim.Adam'><strong><tt>torch.optim.Adam()</tt></strong></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFXysL86993d"
   },
   "outputs": [],
   "source": [
    "# FOR REDO\n",
    "torch.manual_seed(4)\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKuqLcoa993d"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uC3hSkk993d"
   },
   "outputs": [],
   "source": [
    "y_pred = model.forward(X_train)\n",
    "loss = criterion(y_pred, y_train)\n",
    "loss.backward()\n",
    "losses.append(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-gIaT7B993e"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5jn2LdU993e",
    "outputId": "cfaa8329-0bac-4e43-d28b-30299d788320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1  loss: 1.09568226\n",
      "epoch: 11  loss: 0.98190653\n",
      "epoch: 21  loss: 0.75652307\n",
      "epoch: 31  loss: 0.49447522\n",
      "epoch: 41  loss: 0.34981874\n",
      "epoch: 51  loss: 0.22807853\n",
      "epoch: 61  loss: 0.13547322\n",
      "epoch: 71  loss: 0.09162075\n",
      "epoch: 81  loss: 0.07378192\n",
      "epoch: 91  loss: 0.06546164\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%10 == 1:\n",
    "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmEv_dEX993e"
   },
   "source": [
    "## Plot the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6eanNXe993e",
    "outputId": "fd574113-7831-4f2c-810a-7cf6d3d7a5c7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9j6z3L_t993f"
   },
   "source": [
    "## Validate the model\n",
    "Now we run the test set through the model to see if the loss calculation resembles the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_UktqW_993f",
    "outputId": "4a2492ba-f4a8-4837-ffe9-2ca739cdeb34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11568320\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_val = model.forward(X_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'{loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAF9JhhK993f",
    "outputId": "9ac3887f-cf31-46f9-9881-353b65cbf51b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([5.7000, 2.9000, 4.2000, 1.3000])\n",
      "tensor([0.3319, 0.4539, 0.2570], grad_fn=<AddBackward0>)\n",
      "1 tensor([6.7000, 3.1000, 4.4000, 1.4000])\n",
      "tensor([0.3622, 0.4976, 0.3031], grad_fn=<AddBackward0>)\n",
      "2 tensor([4.7000, 3.2000, 1.6000, 0.2000])\n",
      "tensor([0.2318, 0.3671, 0.1407], grad_fn=<AddBackward0>)\n",
      "3 tensor([6.5000, 2.8000, 4.6000, 1.5000])\n",
      "tensor([0.3607, 0.4913, 0.2976], grad_fn=<AddBackward0>)\n",
      "4 tensor([6.1000, 2.6000, 5.6000, 1.4000])\n",
      "tensor([0.3565, 0.4826, 0.3019], grad_fn=<AddBackward0>)\n",
      "5 tensor([6.3000, 3.3000, 6.0000, 2.5000])\n",
      "tensor([0.3797, 0.5122, 0.3296], grad_fn=<AddBackward0>)\n",
      "6 tensor([4.8000, 3.4000, 1.9000, 0.2000])\n",
      "tensor([0.2355, 0.3747, 0.1527], grad_fn=<AddBackward0>)\n",
      "7 tensor([5.1000, 3.5000, 1.4000, 0.3000])\n",
      "tensor([0.2380, 0.3833, 0.1538], grad_fn=<AddBackward0>)\n",
      "8 tensor([6.4000, 3.1000, 5.5000, 1.8000])\n",
      "tensor([0.3686, 0.5013, 0.3175], grad_fn=<AddBackward0>)\n",
      "9 tensor([6.9000, 3.2000, 5.7000, 2.3000])\n",
      "tensor([0.3914, 0.5299, 0.3449], grad_fn=<AddBackward0>)\n",
      "10 tensor([6.8000, 3.2000, 5.9000, 2.3000])\n",
      "tensor([0.3902, 0.5278, 0.3454], grad_fn=<AddBackward0>)\n",
      "11 tensor([4.4000, 3.0000, 1.3000, 0.2000])\n",
      "tensor([0.2208, 0.3511, 0.1201], grad_fn=<AddBackward0>)\n",
      "12 tensor([6.3000, 3.4000, 5.6000, 2.4000])\n",
      "tensor([0.3747, 0.5076, 0.3211], grad_fn=<AddBackward0>)\n",
      "13 tensor([6.1000, 2.9000, 4.7000, 1.4000])\n",
      "tensor([0.3485, 0.4757, 0.2844], grad_fn=<AddBackward0>)\n",
      "14 tensor([6.9000, 3.1000, 5.1000, 2.3000])\n",
      "tensor([0.3870, 0.5237, 0.3307], grad_fn=<AddBackward0>)\n",
      "15 tensor([6.4000, 2.9000, 4.3000, 1.3000])\n",
      "tensor([0.3522, 0.4825, 0.2869], grad_fn=<AddBackward0>)\n",
      "16 tensor([6.0000, 3.0000, 4.8000, 1.8000])\n",
      "tensor([0.3522, 0.4784, 0.2853], grad_fn=<AddBackward0>)\n",
      "17 tensor([5.2000, 3.5000, 1.5000, 0.2000])\n",
      "tensor([0.2390, 0.3861, 0.1586], grad_fn=<AddBackward0>)\n",
      "18 tensor([6.3000, 3.3000, 4.7000, 1.6000])\n",
      "tensor([0.3558, 0.4883, 0.2965], grad_fn=<AddBackward0>)\n",
      "19 tensor([7.2000, 3.2000, 6.0000, 1.8000])\n",
      "tensor([0.3945, 0.5381, 0.3611], grad_fn=<AddBackward0>)\n",
      "20 tensor([4.9000, 3.1000, 1.5000, 0.1000])\n",
      "tensor([0.2351, 0.3722, 0.1450], grad_fn=<AddBackward0>)\n",
      "21 tensor([5.7000, 3.8000, 1.7000, 0.3000])\n",
      "tensor([0.2567, 0.4118, 0.1873], grad_fn=<AddBackward0>)\n",
      "22 tensor([6.5000, 3.0000, 5.8000, 2.2000])\n",
      "tensor([0.3801, 0.5127, 0.3292], grad_fn=<AddBackward0>)\n",
      "23 tensor([4.8000, 3.0000, 1.4000, 0.1000])\n",
      "tensor([0.2325, 0.3669, 0.1383], grad_fn=<AddBackward0>)\n",
      "24 tensor([6.0000, 2.2000, 5.0000, 1.5000])\n",
      "tensor([0.3519, 0.4722, 0.2817], grad_fn=<AddBackward0>)\n",
      "25 tensor([6.2000, 2.8000, 4.8000, 1.8000])\n",
      "tensor([0.3585, 0.4852, 0.2916], grad_fn=<AddBackward0>)\n",
      "26 tensor([6.1000, 3.0000, 4.6000, 1.4000])\n",
      "tensor([0.3474, 0.4753, 0.2830], grad_fn=<AddBackward0>)\n",
      "27 tensor([6.1000, 2.8000, 4.0000, 1.3000])\n",
      "tensor([0.3418, 0.4673, 0.2675], grad_fn=<AddBackward0>)\n",
      "28 tensor([6.5000, 3.0000, 5.2000, 2.0000])\n",
      "tensor([0.3724, 0.5045, 0.3149], grad_fn=<AddBackward0>)\n",
      "29 tensor([5.9000, 3.0000, 5.1000, 1.8000])\n",
      "tensor([0.3518, 0.4773, 0.2881], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(X_test):\n",
    "     print(i, data)\n",
    "     print(model.forward(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5i0j8qT993g",
    "outputId": "a2bc0b58-1e71-4fe5-ab0e-85d7e1d28dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. tensor([-0.3355,  7.3630,  1.3783])     1\n",
      " 2. tensor([0.2775, 8.1554, 0.4269])        1\n",
      " 3. tensor([ 11.9969,   6.1847, -19.1976])  0\n",
      " 4. tensor([-2.0187,  7.9664,  4.2447])     1\n",
      " 5. tensor([-6.1348,  7.9516, 11.0913])     2\n",
      " 6. tensor([-10.2635,   8.3101,  17.9998])  2\n",
      " 7. tensor([ 12.0542,   6.4321, -19.2909])  0\n",
      " 8. tensor([ 12.9507,   6.4819, -20.7540])  0\n",
      " 9. tensor([-5.7723,  8.2435, 10.5083])     2\n",
      "10. tensor([-7.8867,  8.6126, 14.0731])     2\n",
      "11. tensor([-8.7055,  8.6074, 15.4337])     2\n",
      "12. tensor([ 11.6358,   5.8167, -18.6220])  0\n",
      "13. tensor([-8.1009,  8.2331, 14.3888])     2\n",
      "14. tensor([-2.0791,  7.7752,  4.3188])     1\n",
      "15. tensor([-6.0828,  8.3916, 11.0586])     2\n",
      "16. tensor([0.1360, 7.8660, 0.6409])        1\n",
      "17. tensor([-4.0875,  7.7217,  7.6642])     2\n",
      "18. tensor([ 13.1522,   6.5911, -21.0798])  0\n",
      "19. tensor([-1.5644,  8.0222,  3.4754])     1\n",
      "20. tensor([-6.2859,  8.9728, 11.4248])     2\n",
      "21. tensor([ 12.3859,   6.2571, -19.8275])  0\n",
      "22. tensor([ 13.8200,   7.0859, -22.1528])  0\n",
      "23. tensor([-8.8470,  8.3180, 15.6476])     2\n",
      "24. tensor([ 12.1979,   6.1264, -19.5260])  0\n",
      "25. tensor([-5.8084,  7.5468, 10.5340])     2\n",
      "26. tensor([-4.4526,  7.7876,  8.2865])     2\n",
      "27. tensor([-1.4284,  7.7786,  3.2328])     1\n",
      "28. tensor([ 0.5356,  7.5360, -0.0492])     1\n",
      "29. tensor([-5.8230,  8.1573, 10.5975])     2\n",
      "30. tensor([-5.2569,  7.7476,  9.6105])     2\n",
      "\n",
      "29 out of 30 = 96.67% correct\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "        print(f'{i+1:2}. {str(y_val):38}  {y_test[i]}')\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "print(f'\\n{correct} out of {len(y_test)} = {100*correct/len(y_test):.2f}% correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vr3de-KQ993g"
   },
   "source": [
    "Here we can see that #17 was misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97LbvFj6993g"
   },
   "source": [
    "## Save the trained model to a file\n",
    "Right now <strong><tt>model</tt></strong> has been trained and validated, and seems to correctly classify an iris 97% of the time. Let's save this to disk.<br>\n",
    "The tools we'll use are <a href='https://pytorch.org/docs/stable/torch.html#torch.save'><strong><tt>torch.save()</tt></strong></a> and <a href='https://pytorch.org/docs/stable/torch.html#torch.load'><strong><tt>torch.load()</tt></strong></a><br>\n",
    "\n",
    "There are two basic ways to save a model.<br>\n",
    "\n",
    "The first saves/loads the `state_dict` (learned parameters) of the model, but not the model class. The syntax follows:<br>\n",
    "<tt><strong>Save:</strong>&nbsp;torch.save(model.state_dict(), PATH)<br><br>\n",
    "<strong>Load:</strong>&nbsp;model = TheModelClass(\\*args, \\*\\*kwargs)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.load_state_dict(torch.load(PATH))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.eval()</tt>\n",
    "\n",
    "The second saves the entire model including its class and parameters as a pickle file. Care must be taken if you want to load this into another notebook to make sure all the target data is brought in properly.<br>\n",
    "<tt><strong>Save:</strong>&nbsp;torch.save(model, PATH)<br><br>\n",
    "<strong>Load:</strong>&nbsp;model = torch.load(PATH))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;model.eval()</tt>\n",
    "\n",
    "In either method, you must call <tt>model.eval()</tt> to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.\n",
    "\n",
    "For more information visit https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OepfT2Pl993h"
   },
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H24z2PoF993i"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'IrisDatasetModel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKUzx9-V993i"
   },
   "source": [
    "### Load a new model\n",
    "We'll load a new model object and test it as we had before to make sure it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxprRybG993i",
    "outputId": "fcf56ba7-2e95-4a88-e9fb-b5be10b314ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
       "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Model()\n",
    "new_model.load_state_dict(torch.load('IrisDatasetModel.pt'))\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ioD3wB6o993i",
    "outputId": "dae072f5-850b-4edd-9e86-f7e3af68be26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06246195\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_val = new_model.forward(X_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'{loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBeP6vXu993j"
   },
   "source": [
    "## Apply the model to classify new, unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wsi4MaN_993j"
   },
   "outputs": [],
   "source": [
    "mystery_iris = torch.tensor([5.6,3.7,2.2,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Whg3E7Fd993j"
   },
   "source": [
    "Let's plot this new iris in yellow to see where it falls in relation to the others:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vCusCa0993j"
   },
   "source": [
    "Now run it through the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E61zkNO3993j",
    "outputId": "f4a51876-a00b-42c4-991e-840c3ff76cb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 12.2116,   7.1285, -19.5247])\n",
      "\n",
      "Iris setosa\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(new_model(mystery_iris))\n",
    "    print()\n",
    "    print(labels[new_model(mystery_iris).argmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWr7BGBa993k"
   },
   "source": [
    "## Great job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tVUQmJT993k"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classification-PyTorch-NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
